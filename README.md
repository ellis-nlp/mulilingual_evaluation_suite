# Mulilingual Evaluation Suite 
Work on a standardized, wide-coverage, fine-grained test suite for machine translation and cross-lingual langauge understanding (e.g. similar to GEM) 

TODO: Add resources, initial ideas, existing benchmarks which could be integrated into the suite, evaluation aspects that lack useful benchmarks 
